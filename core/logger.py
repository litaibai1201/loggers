# -*- coding: utf-8 -*-
"""
@æ–‡ä»¶: logger.py
@è¯´æ˜: æ—¥å¿—é…ç½®å’Œåˆå§‹åŒ–
@æ—¶é—´: 2024
"""
import logging.config
import socket
import os
import sys
import atexit
from typing import Any, Dict, Optional
from queue import Queue
from logging.handlers import QueueHandler, QueueListener

import structlog
from pydantic import ValidationError

from ..conf import LOGGING_CONFIG
from .models import LogModel

# å…¨å±€å˜é‡ï¼šä¿å­˜ QueueListener å®ä¾‹
_queue_listener: Optional[QueueListener] = None


class LoggerConfig:
    """æ—¥å¿—é…ç½®ç®¡ç†å™¨"""

    @staticmethod
    def get_host_ip() -> str:
        """è·å–æœ¬æœºIPåœ°å€"""
        try:
            return socket.gethostbyname(socket.gethostname())
        except Exception:
            return "unknown"

    @staticmethod
    def validate_log_structure(_logger: Any, _method_name: str, event_dict: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯æ—¥å¿—æ•°æ®ç»“æ„

        Note: _logger å’Œ _method_name æ˜¯ structlog å¤„ç†å™¨æ¥å£è¦æ±‚çš„å‚æ•°,
              è™½ç„¶åœ¨æ­¤æ–¹æ³•ä¸­æœªä½¿ç”¨,ä½†å¿…é¡»ä¿ç•™ä»¥ç¬¦åˆæ¥å£è§„èŒƒ
        """
        try:
            LogModel(**event_dict)
        except ValidationError as e:
            # æ—¥å¿—éªŒè¯å¤±è´¥æ—¶,è®°å½•é”™è¯¯ä½†ä¸ä¸­æ–­ä¸šåŠ¡
            error_logger = logging.getLogger("my.custom.error")
            error_logger.error(
                f"Log validation failed (non-blocking): {str(e)}\n"
                f"Original log data: {event_dict}"
            )
            # ä¸æŠ›å‡ºå¼‚å¸¸,ä¿è¯ä¸šåŠ¡ä»£ç ä¸è¢«ä¸­æ–­
            # æ·»åŠ æ ‡è®°å­—æ®µè¡¨æ˜è¿™æ˜¯ä¸€ä¸ªæ ¼å¼é”™è¯¯çš„æ—¥å¿—
            event_dict["_validation_error"] = str(e)
        event_dict.setdefault("client_ip", LoggerConfig.get_host_ip())
        return event_dict


def configure_logger(use_queue_handler: Optional[bool] = None):
    """åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ

    Args:
        use_queue_handler: æ˜¯å¦ä½¿ç”¨é˜Ÿåˆ—å¤„ç†å™¨ï¼ˆéé˜»å¡æ—¥å¿—è®°å½•ï¼‰
            - None: è‡ªåŠ¨åˆ¤æ–­ï¼ˆæ£€æµ‹ asyncio ç¯å¢ƒæˆ–è¯»å–é…ç½®æ–‡ä»¶ï¼‰
            - True: å¼ºåˆ¶å¯ç”¨ï¼ˆæ¨èç”¨äº FastAPI/AsyncIO/é«˜å¹¶å‘åº”ç”¨ï¼‰
            - False: ç¦ç”¨ï¼ˆæ¨èç”¨äºå¤šè¿›ç¨‹åº”ç”¨æˆ–ä½å¹¶å‘åœºæ™¯ï¼‰

    ä½¿ç”¨åœºæ™¯:
        # åœºæ™¯1: FastAPI/AsyncIO åº”ç”¨
        configure_logger(use_queue_handler=True)

        # åœºæ™¯2: å¤šè¿›ç¨‹åº”ç”¨ (Gunicorn)
        configure_logger(use_queue_handler=False)

        # åœºæ™¯3: è‡ªåŠ¨æ£€æµ‹
        configure_logger()  # ä¼šè‡ªåŠ¨æ£€æµ‹ç¯å¢ƒ

        # åœºæ™¯4: é€šè¿‡ç¯å¢ƒå˜é‡æ§åˆ¶
        # export LOG_USE_QUEUE_HANDLER=true
        configure_logger()
    """
    # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
    _ensure_log_directories()

    # å‡†å¤‡é…ç½®ï¼ˆæ³¨å…¥ç›®å½•è®¾ç½®åˆ°å¤„ç†å™¨ï¼‰
    config = _prepare_logging_config()

    # é…ç½®æ ‡å‡†æ—¥å¿—å¤„ç†å™¨
    logging.config.dictConfig(config)

    # åˆ¤æ–­æ˜¯å¦å¯ç”¨é˜Ÿåˆ—å¤„ç†å™¨
    if use_queue_handler is None:
        # ä¼˜å…ˆä»é…ç½®æ–‡ä»¶è¯»å–
        config_value = LOGGING_CONFIG.get('use_queue_handler')

        if config_value is not None:
            # é…ç½®æ–‡ä»¶ä¸­æ˜ç¡®è®¾ç½®äº†å€¼ï¼ˆTrue æˆ– Falseï¼‰
            use_queue_handler = config_value
        else:
            # é…ç½®æ–‡ä»¶æœªè®¾ç½®ï¼Œè‡ªåŠ¨æ£€æµ‹ asyncio ç¯å¢ƒ
            use_queue_handler = _is_asyncio_environment()

    # è®¾ç½®é˜Ÿåˆ—å¤„ç†å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if use_queue_handler:
        _setup_queue_handler()

    # é…ç½® structlogï¼ˆä½¿ç”¨åŸç”Ÿ contextvars æ”¯æŒï¼‰
    structlog.configure(
        processors=[
            structlog.contextvars.merge_contextvars,  # ğŸ”¥ è‡ªåŠ¨åˆå¹¶ contextvars
            LoggerConfig.validate_log_structure,
            structlog.stdlib.add_log_level,
            structlog.processors.TimeStamper(fmt="iso"),
            structlog.processors.JSONRenderer(ensure_ascii=False),
        ],
        logger_factory=structlog.stdlib.LoggerFactory(),
        wrapper_class=structlog.stdlib.BoundLogger,
        cache_logger_on_first_use=True,
        context_class=dict,  # ä½¿ç”¨ dict ä½œä¸ºä¸Šä¸‹æ–‡å­˜å‚¨
    )


def _prepare_logging_config() -> Dict[str, Any]:
    """å‡†å¤‡æ—¥å¿—é…ç½®ï¼Œæ³¨å…¥ç›®å½•è®¾ç½®åˆ°å¤„ç†å™¨

    Returns:
        ä¿®æ”¹åçš„æ—¥å¿—é…ç½®å­—å…¸
    """
    import copy
    config = copy.deepcopy(LOGGING_CONFIG)

    # è·å–ç›®å½•é…ç½®
    log_dir = config.get('log_dir', 'logs')
    archive_subdir = config.get('archive_subdir', 'archive')
    lock_subdir = config.get('lock_subdir', '.locks')
    max_backup_count = config.get('max_backup_count', 14)

    # è®¡ç®—å®Œæ•´è·¯å¾„
    archive_dir_path = os.path.join(log_dir, archive_subdir)
    lock_dir_path = os.path.join(log_dir, lock_subdir)

    # æ³¨å…¥ç›®å½•é…ç½®åˆ°å¤„ç†å™¨
    handlers = config.get('handlers', {})
    for handler_name, handler_config in handlers.items():
        # å¤„ç†ä½¿ç”¨ OrganizedFileHandler çš„å¤„ç†å™¨
        if 'OrganizedFileHandler' in handler_config.get('class', ''):
            # æ‹¼æ¥å®Œæ•´çš„æ–‡ä»¶è·¯å¾„ï¼ˆlog_dir + filenameï¼‰
            if 'filename' in handler_config:
                filename = handler_config['filename']
                # å¦‚æœ filename ä¸åŒ…å«ç›®å½•ï¼Œåˆ™æ‹¼æ¥ log_dir
                if not os.path.dirname(filename):
                    handler_config['filename'] = os.path.join(log_dir, filename)
            # æ·»åŠ å½’æ¡£ç›®å½•é…ç½®
            handler_config['archive_dir'] = archive_dir_path
            # æ·»åŠ é”æ–‡ä»¶ç›®å½•é…ç½®
            handler_config['lock_dir'] = lock_dir_path
            # ä½¿ç”¨å…¨å±€é…ç½®çš„å¤‡ä»½æ•°é‡ï¼ˆå¦‚æœå¤„ç†å™¨æ²¡æœ‰å•ç‹¬è®¾ç½®ï¼‰
            if 'backupCount' not in handler_config:
                handler_config['backupCount'] = max_backup_count

    return config


def _ensure_log_directories():
    """ç¡®ä¿æ‰€æœ‰æ—¥å¿—ç›®å½•éƒ½å­˜åœ¨ï¼ˆåŒ…æ‹¬å½’æ¡£ç›®å½•å’Œé”æ–‡ä»¶ç›®å½•ï¼‰"""
    # è·å–é…ç½®çš„ç›®å½•
    log_dir = LOGGING_CONFIG.get('log_dir', 'logs')
    archive_subdir = LOGGING_CONFIG.get('archive_subdir', 'archive')
    lock_subdir = LOGGING_CONFIG.get('lock_subdir', '.locks')

    # åˆ›å»ºä¸»æ—¥å¿—ç›®å½•
    if log_dir and not os.path.exists(log_dir):
        os.makedirs(log_dir, exist_ok=True)

    # åˆ›å»ºå½’æ¡£ç›®å½•
    archive_dir = os.path.join(log_dir, archive_subdir)
    if not os.path.exists(archive_dir):
        os.makedirs(archive_dir, exist_ok=True)

    # åˆ›å»ºé”æ–‡ä»¶ç›®å½•
    lock_dir = os.path.join(log_dir, lock_subdir)
    if not os.path.exists(lock_dir):
        os.makedirs(lock_dir, exist_ok=True)

    # ç¡®ä¿ handler é…ç½®ä¸­çš„ç›®å½•ä¹Ÿå­˜åœ¨
    handlers = LOGGING_CONFIG.get("handlers", {})
    for _handler_name, handler_config in handlers.items():
        if "filename" in handler_config:
            log_file = handler_config["filename"]
            file_dir = os.path.dirname(log_file)
            if file_dir and not os.path.exists(file_dir):
                os.makedirs(file_dir, exist_ok=True)


def _is_asyncio_environment() -> bool:
    """æ£€æµ‹æ˜¯å¦è¿è¡Œåœ¨ asyncio ç¯å¢ƒä¸­

    Returns:
        bool: True è¡¨ç¤ºæ£€æµ‹åˆ° asyncio/FastAPI/å¼‚æ­¥æ¡†æ¶
    """
    # æ£€æµ‹å¸¸è§çš„å¼‚æ­¥æ¡†æ¶æ¨¡å—
    async_modules = ['asyncio', 'fastapi', 'aiohttp', 'tornado', 'sanic']
    for module in async_modules:
        if module in sys.modules:
            return True
    return False


def _setup_queue_handler():
    """è®¾ç½®é˜Ÿåˆ—å¤„ç†å™¨ï¼ˆç”¨äº AsyncIO å’Œé«˜å¹¶å‘åœºæ™¯ï¼‰

    å·¥ä½œåŸç†:
        1. åˆ›å»ºçº¿ç¨‹å®‰å…¨çš„é˜Ÿåˆ—
        2. ä¸šåŠ¡çº¿ç¨‹å°†æ—¥å¿—æ”¾å…¥é˜Ÿåˆ—ï¼ˆéé˜»å¡ï¼Œæå¿«ï¼‰
        3. åå°çº¿ç¨‹ä»é˜Ÿåˆ—å–æ—¥å¿—å¹¶å†™å…¥æ–‡ä»¶ï¼ˆä¸²è¡Œï¼Œæ— ç«äº‰ï¼‰

    ä¼˜åŠ¿:
        - ä¸šåŠ¡çº¿ç¨‹ä¸ä¼šè¢«æ–‡ä»¶ I/O é˜»å¡
        - é¿å…å¤šçº¿ç¨‹ç«äº‰æ–‡ä»¶é”ï¼ˆç‰¹åˆ«æ˜¯ Windowsï¼‰
        - AsyncIO åº”ç”¨ä¸ä¼šé˜»å¡äº‹ä»¶å¾ªç¯
    """
    global _queue_listener

    logger = logging.getLogger('my.custom')

    # å¦‚æœå·²ç»è®¾ç½®è¿‡ï¼Œå…ˆåœæ­¢æ—§çš„ç›‘å¬å™¨
    if _queue_listener is not None:
        _queue_listener.stop()

    # ä¿å­˜åŸå§‹çš„ handlers
    original_handlers = logger.handlers[:]

    if not original_handlers:
        # å¦‚æœæ²¡æœ‰ handlersï¼Œç›´æ¥è¿”å›
        return

    # åˆ›å»ºé˜Ÿåˆ—
    queue_size = LOGGING_CONFIG.get('queue_size', -1)
    log_queue = Queue(maxsize=queue_size)

    # åˆ›å»ºé˜Ÿåˆ—å¤„ç†å™¨
    queue_handler = QueueHandler(log_queue)

    # åˆ›å»ºé˜Ÿåˆ—ç›‘å¬å™¨ï¼ˆåœ¨åå°çº¿ç¨‹ä¸­å¤„ç†æ—¥å¿—ï¼‰
    _queue_listener = QueueListener(
        log_queue,
        *original_handlers,
        respect_handler_level=True  # å°Šé‡æ¯ä¸ª handler çš„æ—¥å¿—çº§åˆ«
    )

    # æ›¿æ¢ logger çš„ handlers
    logger.handlers = [queue_handler]

    # å¯åŠ¨åå°ç›‘å¬çº¿ç¨‹
    _queue_listener.start()

    # æ³¨å†Œé€€å‡ºæ—¶åœæ­¢ç›‘å¬å™¨
    atexit.register(_stop_queue_listener)

    # è¾“å‡ºæç¤ºä¿¡æ¯
    import sys
    print("âœ… QueueHandler enabled - Non-blocking logging activated", file=sys.stderr)
    print(
        f"   Queue size: {'unlimited' if queue_size == -1 else queue_size}", file=sys.stderr)
    print(f"   Platform: {sys.platform}", file=sys.stderr)


def _stop_queue_listener():
    """åœæ­¢é˜Ÿåˆ—ç›‘å¬å™¨ï¼ˆåœ¨ç¨‹åºé€€å‡ºæ—¶è°ƒç”¨ï¼‰"""
    global _queue_listener
    if _queue_listener is not None:
        _queue_listener.stop()
        _queue_listener = None


def get_queue_handler_status() -> Dict[str, Any]:
    """è·å–é˜Ÿåˆ—å¤„ç†å™¨çŠ¶æ€ï¼ˆç”¨äºç›‘æ§å’Œè°ƒè¯•ï¼‰

    Returns:
        dict: åŒ…å«çŠ¶æ€ä¿¡æ¯çš„å­—å…¸
    """
    global _queue_listener

    if _queue_listener is None:
        return {
            "enabled": False,
            "message": "QueueHandler is not enabled"
        }

    logger = logging.getLogger('my.custom')
    queue_handler = None

    # æŸ¥æ‰¾ QueueHandler
    for handler in logger.handlers:
        if isinstance(handler, QueueHandler):
            queue_handler = handler
            break

    if queue_handler is None:
        return {
            "enabled": False,
            "message": "QueueHandler not found in logger handlers"
        }

    queue = queue_handler.queue
    return {
        "enabled": True,
        "queue_size_current": queue.qsize(),
        "queue_size_max": queue.maxsize if queue.maxsize > 0 else "unlimited",
        "message": "QueueHandler is running"
    }


